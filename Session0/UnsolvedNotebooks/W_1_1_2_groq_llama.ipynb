{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mabdulhadi/360monodepth/blob/main/Session0/UnsolvedNotebooks/W_1_1_2_groq_llama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B81HaqajHOgO"
      },
      "source": [
        "# First Agentic AI workflow with Groq and Llama- LLM(Free of cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOeOVcoEHOgQ"
      },
      "outputs": [],
      "source": [
        "# First let's do an import\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzvYILabHOgR"
      },
      "outputs": [],
      "source": [
        "# Next it's time to load the API keys into environment variables\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQB3CAUXHOgS"
      },
      "outputs": [],
      "source": [
        "# Check the Groq API key\n",
        "\n",
        "import os\n",
        "groq_api_key = os.getenv('GROQ_API_KEY'). # add your API key here: ##################\n",
        "\n",
        "if groq_api_key:\n",
        "    print(f\"GROQ API Key exists and begins {groq_api_key[:8]}\")\n",
        "else:\n",
        "    print(\"GROQ API Key not set\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMABNBcFHOgS"
      },
      "outputs": [],
      "source": [
        "# And now - the all important import statement\n",
        "# If you get an import error - head over to troubleshooting guide\n",
        "\n",
        "from groq import Groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf7a9WP3HOgT"
      },
      "outputs": [],
      "source": [
        "# Create a Groq instance\n",
        "groq = Groq()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLgYw5iYHOgU"
      },
      "outputs": [],
      "source": [
        "# Create a list of messages in the familiar Groq format\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1WrUYcxHOgV"
      },
      "outputs": [],
      "source": [
        "# And now call it!\n",
        "\n",
        "response = groq.chat.completions.create(model='llama-3.3-70b-versatile', messages=messages)\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3zkxX1uHOgV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j-gU1lSHOgV"
      },
      "outputs": [],
      "source": [
        "# And now - let's ask for a question:\n",
        "\n",
        "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
        "messages = [{\"role\": \"user\", \"content\": question}]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dd2h2HzHOgW"
      },
      "outputs": [],
      "source": [
        "# ask it\n",
        "response = groq.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "question = response.choices[0].message.content\n",
        "\n",
        "print(question)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpCKGEV_HOgX"
      },
      "outputs": [],
      "source": [
        "# form a new messages list\n",
        "messages = [{\"role\": \"user\", \"content\": question}]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTK5tovkHOgX"
      },
      "outputs": [],
      "source": [
        "# Ask it again\n",
        "\n",
        "response = groq.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "answer = response.choices[0].message.content\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUX_1deXHOgX"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "display(Markdown(answer))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise"
      ],
      "metadata": {
        "id": "oG52GOVqH14h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUP6r3wuHOgY"
      },
      "outputs": [],
      "source": [
        "# First create the messages:\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": \"Give me a business area that might be ripe for an Agentic AI solution.\"}]\n",
        "\n",
        "# Then make the first call:\n",
        "\n",
        "response = groq.chat.completions.create(model='llama-3.3-70b-versatile', messages=messages)\n",
        "\n",
        "# Then read the business idea:\n",
        "\n",
        "business_idea = response.choices[0].message.content\n",
        "\n",
        "\n",
        "# And repeat!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0bHcutuHOgY"
      },
      "outputs": [],
      "source": [
        "\n",
        "display(Markdown(business_idea))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcuNNUDwHOgY"
      },
      "outputs": [],
      "source": [
        "# Update the message with the business idea from previous step\n",
        "messages = [{\"role\": \"user\", \"content\": \"What is the pain point in the business area of \" + business_idea + \"?\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iAh-DCYHOgY"
      },
      "outputs": [],
      "source": [
        "# Make the second call\n",
        "response = groq.chat.completions.create(model='llama-3.3-70b-versatile', messages=messages)\n",
        "# Read the pain point\n",
        "pain_point = response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMNYUl3lHOgY"
      },
      "outputs": [],
      "source": [
        "display(Markdown(pain_point))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzQX2lFMHOgY"
      },
      "outputs": [],
      "source": [
        "# Make the third call\n",
        "messages = [{\"role\": \"user\", \"content\": \"What is the Agentic AI solution for the pain point of \" + pain_point + \"?\"}]\n",
        "response = groq.chat.completions.create(model='llama-3.3-70b-versatile', messages=messages)\n",
        "# Read the agentic solution\n",
        "agentic_solution = response.choices[0].message.content\n",
        "display(Markdown(agentic_solution))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTa29QtuHOgY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}